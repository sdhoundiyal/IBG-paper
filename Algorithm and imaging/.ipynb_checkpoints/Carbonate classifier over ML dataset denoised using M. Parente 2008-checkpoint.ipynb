{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import required package\n",
    "from __future__ import division\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import spectral.io.envi as envi\n",
    "from spectral import *\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import PIL\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "import traceback\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import r2_score\n",
    "#from osgeo import gdal\n",
    "from pysptools import spectro\n",
    "from collections import Counter\n",
    "import csv\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file mangement generates a list containing a pth to all hdr files of pre-processed observations\n",
    "def get_all_processed_HDR_addresses(parentDirectory):\n",
    "    observationFiles=[]\n",
    "    \n",
    "    for (dirpath, dirnames, filenames) in os.walk(parentDirectory):\n",
    "        observationFiles.extend(filenames)\n",
    "        break\n",
    "    ObservationImageAddresses=[]\n",
    "    \n",
    "    hdrPattern=\".hdr\"\n",
    "    for i in observationFiles:\n",
    "        if re.search(hdrPattern,i):\n",
    "            ObservationImageAddresses.append(parentDirectory+'/'+i)\n",
    "    return ObservationImageAddresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read hrd files for wavlengths of all bands\n",
    "def read_CRISM_Image_wavelengths(headerFileAddress):\n",
    "    wavelengthFile=\"J:/IIT/user/Documents/CRISM Multispectral Exploration/Processed_observations/wavelength_list.txt\"\n",
    "    \n",
    "    currentObservationHeader=envi.open(headerFileAddress)\n",
    "    currentObservationImage=currentObservationHeader.open_memmap()\n",
    "    currentObservationArray=np.array(currentObservationImage)\n",
    "    #currentObservationArray=spectral.open_image(i)\n",
    "\n",
    "    #read wavelengths from saved wavelength file\n",
    "    with open (wavelengthFile, 'rb') as fp:\n",
    "        wavelengthsOfCurrentObservation=pickle.load(fp)\n",
    "    return currentObservationArray,wavelengthsOfCurrentObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find index of wavelngth closest to given wavelength\n",
    "def find_nearest(wavelength_list,value): #find wavelength value in list closest to given value\n",
    "    idx = np.searchsorted(wavelength_list, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(wavelength_list) or math.fabs(value - wavelength_list[idx-1]) < math.fabs(value - wavelength_list[idx])):\n",
    "        return wavelength_list[idx-1]\n",
    "    else:\n",
    "        return wavelength_list[idx]\n",
    "\n",
    "def find_wavelength_index(wavelength_list,item): #return index of in the array\n",
    "    first = 0\n",
    "    last = len(wavelength_list)-1\n",
    "    found = False\n",
    "    while( first<=last and not found):\n",
    "        mid = (first + last)//2\n",
    "        if wavelength_list[mid] == item :\n",
    "            found = True\n",
    "        else:\n",
    "            if item < wavelength_list[mid]:\n",
    "                last = mid - 1\n",
    "            else:\n",
    "                first = mid + 1\t\n",
    "    return mid\n",
    "def find_nearest_index(wavelength_list,wavelength): #get wavelength in index closest to gicen wavelength and return its index\n",
    "    (nearest_index,nearest_wavelength)=min(enumerate(wavelength_list), key=lambda x: abs(x[1]-wavelength))\n",
    "    return nearest_index\n",
    "def find_nearest_index_for_list(wavelength_list,wavelengths): # find index of nearest value for a list of given values\n",
    "    indices=[]\n",
    "    for i in wavelengths:\n",
    "        indices.append(find_nearest_index(wavelength_list,i))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a hyperspectral datacube and wavelengths to serve as upper and lower thresholds subset the datacube along the spectral direction\n",
    "def get_spectral_subset(datacube,wavelength_list,lower_threshold,upper_threshold): #returns spectral subset from lower to upper threshold ( 1.2 to 2.6 micrometer for CRISM IR)\n",
    "    lower_threshold_index=find_wavelength_index(wavelength_list,lower_threshold)\n",
    "    upper_threshold_index=find_wavelength_index(wavelength_list,upper_threshold)\n",
    "    thresholdedDatacube=datacube[:,:,lower_threshold_index:upper_threshold_index+1]\n",
    "    thresholdedWavelengthList=wavelength_list[lower_threshold_index:upper_threshold_index+1]\n",
    "    return thresholdedDatacube,thresholdedWavelengthList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return an array of objects of SLI files corresponding to different mineral spectra\n",
    "def getspectralObjects(spectraDirectory):\n",
    "    observationFiles=[]\n",
    "    for (_,_,temporaryList) in os.walk(spectraDirectory):\n",
    "        observationFiles.extend(temporaryList)\n",
    "        break\n",
    "    hdrPattern=\".hdr$\"\n",
    "    spectralObjects=[]\n",
    "    for i in observationFiles:\n",
    "        if re.search(hdrPattern,i):\n",
    "            currentFile=spectraDirectory+'/'+i\n",
    "            currentSpectra=envi.open(currentFile)\n",
    "            spectralObjects.append(currentSpectra)\n",
    "    return spectralObjects,observationFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectral object and a wavelength list extract spectra resample them to the given wavelenght list resolution\n",
    "def getResampledSpectra(spectralObject,wavelengthList):\n",
    "    #read an NxM numpy array containing N spectra with M bands\n",
    "    spectras=spectralObject.spectra \n",
    "    #read an array with wavelengths corresponding to each band\n",
    "    sourceWavelengthList=spectralObject.bands.centers \n",
    "    #find no of bands in CRISM image\n",
    "    noOfBands=np.shape(wavelengthList)[0] \n",
    "    # calculate number of spectras\n",
    "    noOfSpectra=np.shape(spectras)[0]\n",
    "    # create an array to store the resampled spectras\n",
    "    resampledSpectras=np.zeros((noOfSpectra,noOfBands))\n",
    "    #create a resampler\n",
    "    resampler=BandResampler(sourceWavelengthList,wavelengthList)\n",
    "    #iterate over all spectra\n",
    "    for i in range(noOfSpectra):\n",
    "        #resample a spectra\n",
    "        resampledSpectras[i,:]=resampler(spectras[i,:])\n",
    "    return resampledSpectras,spectralObject.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given spectral object get original spectra and accompaning wavelength list\n",
    "def getOriginalSpectra(spectralObject):\n",
    "    #read an NxM numpy array containing N spectra with M bands\n",
    "    spectras=spectralObject.spectra \n",
    "    #read an array with wavelengths corresponding to each band\n",
    "    sourceWavelengthList=spectralObject.bands.centers \n",
    "    \n",
    "    return spectras,spectralObject.names,sourceWavelengthList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold image at 2.6 micrometer\n",
    "def preProcessImage(imageHeaderAddress): # given address of a CRISM header file, read the data, deal with NaN values and apply spectral subset\n",
    "    datacube,wavelength_list=read_CRISM_Image_wavelengths(imageHeaderAddress) #read image and wavelength_list\n",
    "    datacube=np.where(np.logical_and(datacube>0,datacube<1),datacube,0)\n",
    "    lower_threshold_for_spectral_subset=1.0\n",
    "    upper_threshold_for_spectral_subset=2.59 #define wavelength threshold (CRISM data too noisy post 2.6 micrometer)\n",
    "    datacube,wavelength_list=get_spectral_subset(datacube,wavelength_list,lower_threshold_for_spectral_subset,upper_threshold_for_spectral_subset)\n",
    "    return datacube,wavelength_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra apply a DoG(difference of gaussian) filter to the spectra with sigmas 7 and 4\n",
    "def applyDoG(spectra,sigma1,sigma2):\n",
    "    #apply gaussian filter with the first sigma\n",
    "    gauss1Filtered=ndimage.gaussian_filter1d(spectra,sigma=sigma1)\n",
    "    #apply gaussian filter with the second sigma\n",
    "    gauss2Filtered=ndimage.gaussian_filter1d(spectra,sigma=sigma2)\n",
    "    #calculate DoG\n",
    "    differenceSpectra=np.abs(np.subtract(gauss2Filtered,gauss1Filtered))\n",
    "    return differenceSpectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given the spectra and indices of minimas interpolate leniar segmaents between the minimas\n",
    "def interpolateBetweenIndices(spectra,indices):\n",
    "    global wavelengthList\n",
    "    #create linear interpolator using wavelengths and reflectance at minima indices\n",
    "    interpolator=interpolate.interp1d(wavelengthList[indices],spectra[indices],kind='linear')\n",
    "    #get interpolated values at all indices\n",
    "    interpolatedReflectance=interpolator(wavelengthList)\n",
    "    return interpolatedReflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra and fraction size apply a boxcar (moving average) filter of that size to the spectra\n",
    "def applyBoxcarFilter(spectra,filterFraction):\n",
    "    #get number of bands in the spectra\n",
    "    bands=np.shape(spectra)[0]\n",
    "    #compute size of the filter\n",
    "    filterSize=int(math.floor(filterFraction*bands))\n",
    "    #cimpute half filter size\n",
    "    halfFilterSize=int(math.floor(filterSize/2))\n",
    "    #symetrically pad the spectra with half the filter size on each end\n",
    "    paddedSpectra=np.pad(spectra,pad_width=halfFilterSize,mode='symmetric')\n",
    "    #create an empty array to store the filtered spectra\n",
    "    filteredSpectra=np.zeros_like(spectra)\n",
    "    #create a counter to store filtered value\n",
    "    index=0\n",
    "    #iterate in original spectra range  in the padded spectra\n",
    "    for i in range(halfFilterSize,halfFilterSize+bands):\n",
    "        #apply the filter and store the result\n",
    "        filteredSpectra[index]=np.sum(paddedSpectra[i-halfFilterSize:i+halfFilterSize])/filterSize\n",
    "        #increment the counter\n",
    "        index=index+1\n",
    "    return filteredSpectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a signal and size of filter find the standard deviation signal\n",
    "def getStandardDeviation(signal,windowSize):\n",
    "    c1=ndimage.filters.uniform_filter(signal,windowSize, mode='reflect')\n",
    "    c2=ndimage.filters.uniform_filter(signal*signal,windowSize, mode='reflect')\n",
    "    return np.sqrt(c2 - c1*c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a signal smmoth it adaptively\n",
    "def adaptiveSmoothing(signal):\n",
    "    #specify box car filter sizes 5% and 15%\n",
    "    firstBoxCarSize=0.05\n",
    "    secondBoxCarSize=0.15\n",
    "    #specify the sigma and window fraction\n",
    "    fraction1=1/15\n",
    "    fraction2=1/25\n",
    "    #specify the standard deviation for the diffrence of Gaussian filters\n",
    "    sigma1=15\n",
    "    sigma2=4\n",
    "    #specify window size of standard deviation calculation\n",
    "    stdWindowSize1=int(fraction1*np.shape(signal)[0])\n",
    "    stdWindowSize2=int(fraction2*np.shape(signal)[0])\n",
    "    #apply 2% box car filter twice\n",
    "    boxcar2Spectra=applyBoxcarFilter(applyBoxcarFilter(signal,filterFraction=firstBoxCarSize),filterFraction=firstBoxCarSize)\n",
    "    #apply 10% box car filter twice\n",
    "    boxcar10Spectra=applyBoxcarFilter(applyBoxcarFilter(signal,filterFraction=firstBoxCarSize),filterFraction=firstBoxCarSize)\n",
    "    #apply DoG on 2% box car\n",
    "    dog2Spectra=applyDoG(boxcar2Spectra,sigma1,sigma2)\n",
    "    #apply DoG on 10% box car\n",
    "    dog10Spectra=applyDoG(boxcar10Spectra,sigma1,sigma2)\n",
    "    #calculate standard deviation for both dog results\n",
    "    dog2STD=getStandardDeviation(dog2Spectra,stdWindowSize1)\n",
    "    dog10STD=getStandardDeviation(dog10Spectra,stdWindowSize2)\n",
    "    #get smmothed spectra\n",
    "    smothedSpectra=np.where(dog2STD<dog10STD,boxcar2Spectra,boxcar10Spectra)\n",
    "    return smothedSpectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra normalize it to the range (0,1)\n",
    "def normalizeSpectra(spectra):\n",
    "    #spectra/=np.max(np.abs(spectra),axis=0)\n",
    "    #return spectra\n",
    "    return (spectra - np.min(spectra))/np.ptp(spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra and the indices of local minimas find the maximas for each segment demarkated by two minimas\n",
    "def getMaximas(spectra,minimaIndices):\n",
    "    #add the end of the spectra to the list of minimas and sort\n",
    "    minimaIndices.append(len(spectra)-1)\n",
    "    minimaIndices.sort()\n",
    "    #create an empty list to store maximas\n",
    "    maximaIndices=[]\n",
    "    #iterate from 1st to the penultimate element\n",
    "    for i in range(len(minimaIndices)-1):\n",
    "        #extract slice of the spectra\n",
    "        spectralSlice=list(spectra[minimaIndices[i]:minimaIndices[i+1]])\n",
    "        #extract slice of the hull\n",
    "        #append the maxima in this segment to the list of maximas\n",
    "        try:\n",
    "            maximaIndices.append(spectralSlice.index(max(spectralSlice))+minimaIndices[i])\n",
    "        except:\n",
    "            pass\n",
    "    return maximaIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra and a hull for the spectra return pait indices marking areas of the spectra that rise aboive the hull\n",
    "def getOverUnderHullSegments(spectra,hull):\n",
    "    #and empty list to hold start and end index of segments over/under the hull and a flag to tell if the segment is above or below\n",
    "    segmentMarkers=[]\n",
    "    #subtract the hull from the input spectra\n",
    "    differenceSpectra=np.subtract(spectra,hull)\n",
    "    #get indices of crossover zeros in the difference spectra\n",
    "    crossoverIndices=list(np.where(np.diff(np.signbit(differenceSpectra)))[0])\n",
    "    #add the start and end of the spectra to the list of cross over points\n",
    "    crossoverIndices.append(0)\n",
    "    crossoverIndices.append(len(spectra)-1)\n",
    "    #remove duplicates and sort\n",
    "    crossoverIndices=list(set(crossoverIndices))\n",
    "    crossoverIndices.sort()\n",
    "    #iterate through segments marked by crossover points\n",
    "    for i in range(len(crossoverIndices)-1):     \n",
    "        #extract segment from the difference signal\n",
    "        currentSegment=differenceSpectra[crossoverIndices[i]:crossoverIndices[i+1]]\n",
    "        postivemagnitude=0\n",
    "        negetivemagnitude=0\n",
    "        #get maginutude of largest postive value in the segment\n",
    "        try:\n",
    "            postivemagnitude=np.max(currentSegment[np.where(currentSegment>0)[0]])\n",
    "        except:\n",
    "            postivemagnitude=0\n",
    "        #get maginutude of largest postive value in the segment\n",
    "        try:\n",
    "            negetivemagnitude=abs(np.min(currentSegment[np.where(currentSegment<0)[0]]))\n",
    "        except:\n",
    "            negetivemagnitude=0    \n",
    "        #calculate sum of the segment check if it is positve or negetive and add to the list\n",
    "        if postivemagnitude>negetivemagnitude:\n",
    "            segmentMarkers.append([crossoverIndices[i],crossoverIndices[i+1],1])\n",
    "        else:\n",
    "            segmentMarkers.append([crossoverIndices[i],crossoverIndices[i+1],-1])\n",
    "    return differenceSpectra,segmentMarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra,set of initial minima Points and an initial hull iteratively improve upon it\n",
    "def generateIdealHull(spectra,initialHull,minimaIndices,hullIndices):\n",
    "    #get markers for segments above or below the hull\n",
    "    differenceSpectra,segmentMarkers=getOverUnderHullSegments(spectra,initialHull)\n",
    "    for i in segmentMarkers:\n",
    "        #get starting index of segment\n",
    "        startIndex=i[0]\n",
    "        #get ending index of segment\n",
    "        endIndex=i[1]\n",
    "        #over or under\n",
    "        overUnderFlag=i[2]\n",
    "        #if the flag is over add the maxima of that segment to the list of hull points and cross over points to minima indices\n",
    "        if overUnderFlag==1:\n",
    "            hullIndices.append(np.argmax(differenceSpectra[startIndex:endIndex])+startIndex)\n",
    "            minimaIndices.append(startIndex)\n",
    "            minimaIndices.append(endIndex)\n",
    "    \n",
    "    #remove duplicates from hull indices and minima indices and sort\n",
    "    hullIndices=list(set(hullIndices))\n",
    "    hullIndices.sort()\n",
    "    minimaIndices=list(set(minimaIndices))\n",
    "    minimaIndices.sort()\n",
    "    #interpolate between maximas to get the hull\n",
    "    hull=interpolateBetweenIndices(spectra,hullIndices)\n",
    "    return hullIndices,hull,minimaIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra get hull points based on an alternate method\n",
    "def getInitialHull(spectra):\n",
    "    #apply  box car filter twice\n",
    "    smoothedSpectra=adaptiveSmoothing(spectra)\n",
    "    \n",
    "    #calculate indices of minima for both versions of smoothed spectra\n",
    "    minimaIndices=list(signal.argrelextrema(smoothedSpectra,np.less)[0])\n",
    "    \n",
    "    #calculate indices of maximas for smoothed spectra\n",
    "    hullIndices=getMaximas(spectra,minimaIndices)\n",
    "    \n",
    "    #append the first and last point in the spectra to close the hull\n",
    "    hullIndices.append(0)\n",
    "    hullIndices.append(len(spectra)-1)\n",
    "    hullIndices.sort()\n",
    "    \n",
    "    #interpolate between maximas to get the hull\n",
    "    hull=interpolateBetweenIndices(spectra,hullIndices)\n",
    "    \n",
    "    return hullIndices,hull,minimaIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra and indices of its hull points check if 2 or more hull points are between 2.1 and 2.4 micrometer\n",
    "#if find all hull points with low smoothing ahead of the index corresponding to the hull point closest to 2.1 micrometer\n",
    "def getOhHullPoints(crSpectra,hullPoints):\n",
    "    #specify check range\n",
    "    lowerWavelengthBound=2.1\n",
    "    upperWavelengthBound=2.5\n",
    "    #get wavlengths corresponding to hull points\n",
    "    global wavelengthList\n",
    "    hullPointWavelengths=wavelengthList[hullPoints]\n",
    "    #get indices of hull points in the wavelength bound\n",
    "    boundedIndices=np.array(hullPoints)[np.where(np.logical_and(hullPointWavelengths>=lowerWavelengthBound,hullPointWavelengths<=upperWavelengthBound))[0].tolist()]\n",
    "    \n",
    "    #check if there is only 1 elements if so return the original list of hull points\n",
    "    if len(boundedIndices)<2:\n",
    "        return hullPoints\n",
    "    #calculate diffence between succesive indices\n",
    "    indicesDifference=np.absolute(np.subtract(boundedIndices[:-1],boundedIndices[1:])).tolist()\n",
    "    #check if all consecitive indices whose difference is less than 10 and return original list of hull points\n",
    "    if all(i <10 for i in indicesDifference):\n",
    "        return hullPoints\n",
    "    \n",
    "    #get the index for the first hull point in bounds\n",
    "    breakPointIndex=boundedIndices[0]\n",
    "    #extract portion of the continuum removed spectra after the breakPointIndex\n",
    "    spectraSegment=applyBoxcarFilter(crSpectra,0.02)[breakPointIndex:]\n",
    "    \n",
    "    #get maxima indices\n",
    "    maximaIndices=list(signal.argrelextrema(spectraSegment,np.greater)[0])\n",
    "    return maximaIndices+breakPointIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a continuum removed spectra remove any segments that are less than 6 points wide or whose average value is more than 0.99\n",
    "def removeNonSegments(crSpectra):\n",
    "    #create an array to hold processed spectra\n",
    "    processedSpectra=np.ones_like(crSpectra)\n",
    "    #get hull point indices i.e where continuum removed spectra equals 1\n",
    "    hullPointIndices=np.where(crSpectra==1)[0]\n",
    "    #iterate between consecutive hull points\n",
    "    for i in range(len(hullPointIndices)-1):\n",
    "        #extract spectral slice between current pair of hull points\n",
    "        currentSpectralSlice=crSpectra[hullPointIndices[i]:hullPointIndices[i+1]]\n",
    "        #calculate length of current spectral slice\n",
    "        sliceLength=np.shape(currentSpectralSlice)[0]\n",
    "        #if length of the slice is more than 5 and mean is less than 0.95 keep the slice\n",
    "        if sliceLength>5 and np.min(currentSpectralSlice)<0.99:\n",
    "              processedSpectra[hullPointIndices[i]:hullPointIndices[i+1]]=currentSpectralSlice\n",
    "    return processedSpectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a continuum removed spectra identify maximas between consecutive hull points and set the maximum maxima whose value is also greater than an absolute threshold to be a hull points\n",
    "def finalAdjustments(crSpectra,hullIndices):\n",
    "    #set points in the continuum removed spectra at hull indices equal to 1\n",
    "    crSpectra[hullIndices]=1.0\n",
    "    return crSpectra,hullIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra calculate the hull points and hull for using 2 different levels of smoothing and plot the results\n",
    "def plotHull(normalizedSpectra):\n",
    "    #get hull indices for both levels of smoothing\n",
    "    hullIndices,hull,minimaIndices=getInitialHull(normalizedSpectra)\n",
    "    #iteratively improve both hulls\n",
    "    while(True):\n",
    "        #save hulls from previous iterations\n",
    "        prevHull=hull\n",
    "        #improve the hull\n",
    "        hullIndices,hull,minimaIndices=generateIdealHull(normalizedSpectra,hull,minimaIndices,hullIndices)\n",
    "        #if no improvements occoured in the hull exit\n",
    "        if (prevHull==hull).all():\n",
    "            break\n",
    "    #find any points that rise above the continuum\n",
    "    hullAdditionalPoints=np.where(np.divide(normalizedSpectra,hull)>1)[0]\n",
    "    #add those points to hull points\n",
    "    hullIndices.extend(hullAdditionalPoints)\n",
    "    #remove any duplicates and sort\n",
    "    hullIndices=list(set(hullIndices))\n",
    "    hullIndices.sort()\n",
    "    #interpolate between points to get final hull\n",
    "    hull=interpolateBetweenIndices(normalizedSpectra,hullIndices)\n",
    "    #remove the continuum\n",
    "    cr=np.ones_like(normalizedSpectra)\n",
    "    cr=np.divide(normalizedSpectra,hull,out=cr,where=hull!=0)\n",
    "    #get OH hull points\n",
    "    hullIndices.extend(getOhHullPoints(cr,hullIndices))\n",
    "    #interpolate a hull\n",
    "    hull=interpolateBetweenIndices(normalizedSpectra,hullIndices)\n",
    "    \n",
    "    #find any points that rise above the continuum\n",
    "    hullAdditionalPoints=np.where(np.divide(normalizedSpectra,hull)>1)[0]\n",
    "    #add those points to hull points\n",
    "    hullIndices.extend(hullAdditionalPoints)\n",
    "    #remove any duplicates and sort\n",
    "    hullIndices=list(set(hullIndices))\n",
    "    hullIndices.sort()\n",
    "    #interpolate between points to get final hull\n",
    "    hull=interpolateBetweenIndices(normalizedSpectra,hullIndices)\n",
    "    \n",
    "    #remove the continuum\n",
    "    cr=np.ones_like(normalizedSpectra)\n",
    "    cr=np.divide(normalizedSpectra,hull,out=cr,where=hull!=0)\n",
    "    #make final adjustments to the continuum removed spectra\n",
    "    cr,hullIndices=finalAdjustments(cr,hullIndices)\n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a datacube return its footprint i.e pixels in and out of the scene\n",
    "def getDatacubeFootprint(datacube):\n",
    "    [row,col,bands]=np.shape(datacube)\n",
    "    #create an array to hold footprint of the image\n",
    "    footprint=np.zeros_like(datacube[:,:,0])\n",
    "    #get foot print of in scene pixels\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if 0==datacube[i,j,:].all():\n",
    "                footprint[i,j]=1\n",
    "    return footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra normalize it to the range (0,1)\n",
    "def normalizeSpectra(spectra):\n",
    "    upperLimit=1\n",
    "    lowerLimit=0.0000001\n",
    "    maximumValue=np.amax(spectra)\n",
    "    minimumValue=np.amin(spectra)\n",
    "    normalizedSpectra=(upperLimit-lowerLimit)*(spectra-minimumValue)/(maximumValue-minimumValue)+lowerLimit\n",
    "    return normalizedSpectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a continuum removed spectra get the start and ending points of all absorption features\n",
    "def getHullPoints(crSpectra):\n",
    "    #create a empty lists to store hull\n",
    "    hullPoints=[]\n",
    "    #get indices for all 1s n the continuum removed spectra\n",
    "    onePoints=list(np.where(crSpectra==1)[0])\n",
    "    for i in range(len(onePoints)-1):\n",
    "        if onePoints[i]!=onePoints[i+1]-1 or onePoints[i-1]+1!=onePoints[i]:\n",
    "            hullPoints.append(onePoints[i])\n",
    "    #add starting and ending point of spectra\n",
    "    hullPoints.append(0)\n",
    "    hullPoints.append(np.shape(crSpectra)[0]-1)\n",
    "    #remove any duplicates and sort\n",
    "    hullPoints=list(set(hullPoints))\n",
    "    hullPoints.sort()\n",
    "    \n",
    "    #create 2 empty lists to hold starting and ending points of absorption features\n",
    "    startPoints=[]\n",
    "    endPoints=[]\n",
    "    for i in range(len(hullPoints)-1):\n",
    "        #get a spectral slice between the ith and i+1th hull point\n",
    "        spectralSlice=crSpectra[hullPoints[i]:hullPoints[i+1]]\n",
    "        #if mean of spectral slice is more than 0.99 it is not an absorption feature\n",
    "        if np.mean(spectralSlice)<0.99:\n",
    "            startPoints.append(hullPoints[i])\n",
    "            endPoints.append(hullPoints[i+1])\n",
    "    return startPoints,endPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a continuum removed spectra extract each spectral feature and return 2 lists one of the spectra features and the other wavelengths for each feature\n",
    "def getAbsorptionFeatures(crSpectra):\n",
    "    global wavelengthList\n",
    "    startPoints,endPoints=getHullPoints(crSpectra)\n",
    "    #create two empty lists to hold reflectances and wavelengths for absorption features\n",
    "    features=[]\n",
    "    wavelengths=[]\n",
    "    for i in range(len(startPoints)):\n",
    "        featureReflectance=crSpectra[startPoints[i]:endPoints[i]+1]\n",
    "        featureWavelengths=wavelengthList[startPoints[i]:endPoints[i]+1]\n",
    "        features.append(featureReflectance)\n",
    "        wavelengths.append(featureWavelengths)\n",
    "    return features,wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a absorption feature get its parameters\n",
    "def getAbsorbanceParametersPolynomial(currentWavelength,currentReflectance):\n",
    "    #set number of points to interpolate on each side\n",
    "    noOfPoints=20\n",
    "    \n",
    "    #get band centre as band minima\n",
    "    bandCentre=currentWavelength[np.argmin(currentReflectance)]\n",
    "    #get band depth\n",
    "    bandDepth=np.max(currentReflectance)-currentReflectance[np.argmin(currentReflectance)]\n",
    "    \n",
    "    #create array to hold left half of the feature\n",
    "    leftFeaturePoints=[]\n",
    "    #create array to hold right half of the feature\n",
    "    rightFeaturePoints=[]\n",
    "    #create array to hold left half of wavelengths\n",
    "    leftWavelengthPoints=[]\n",
    "    #create array to hold right half of wavelengths\n",
    "    rightWavelengthPoints=[]\n",
    "    \n",
    "    #check if there are set no. of points to the left of the band minima and extract 10 points to the left, if less than 10 extract all points\n",
    "    if np.argmin(currentReflectance)>noOfPoints:\n",
    "        leftFeaturePoints=currentReflectance[np.argmin(currentReflectance)-noOfPoints:np.argmin(currentReflectance)]\n",
    "        leftWavelengthPoints=currentWavelength[np.argmin(currentReflectance)-noOfPoints:np.argmin(currentReflectance)]\n",
    "    else:\n",
    "        leftFeaturePoints=currentReflectance[:np.argmin(currentReflectance)]\n",
    "        leftWavelengthPoints=currentWavelength[:np.argmin(currentReflectance)]\n",
    "    #check if there are set no. of points to the right of the band minima and extract 10 points to the right, if less than 10 extract all points\n",
    "    if np.argmin(currentReflectance)-np.shape(currentReflectance)[0]>noOfPoints:\n",
    "        rightFeaturePoints=currentReflectance[np.argmin(currentReflectance):np.argmin(currentReflectance)-noOfPoints]\n",
    "        rightWavelengthPoints=currentWavlength[np.argmin(currentReflectance):np.argmin(currentReflectance)-noOfPoints]\n",
    "    else:\n",
    "        rightFeaturePoints=currentReflectance[np.argmin(currentReflectance):]\n",
    "        rightWavelengthPoints=currentWavelength[np.argmin(currentReflectance):]\n",
    "    \n",
    "    #combine the left and right lists\n",
    "    wavelength=np.concatenate((leftWavelengthPoints,rightWavelengthPoints))\n",
    "    reflectance=np.concatenate((leftFeaturePoints,rightFeaturePoints))\n",
    "        \n",
    "    \n",
    "    #get step size as 1/4 of the difference between consecutive bands\n",
    "    bandWidth=abs(wavelength[0]-wavelength[1])\n",
    "    stepSize=bandWidth/4\n",
    "    #generate list of interpolated wavelengths\n",
    "    interpolatedWavelengths=np.arange(wavelength[0],wavelength[-1],stepSize)\n",
    "    #fit a polynomial to the data\n",
    "    polynomial=np.poly1d(np.polyfit(wavelength,reflectance,4))\n",
    "    polynomialReflectance=polynomial(interpolatedWavelengths)\n",
    "    #get band centre\n",
    "    bandCentre=currentWavelength[np.argmin(currentReflectance)]\n",
    "    #get band depth\n",
    "    bandDepth=1-polynomial(bandCentre)\n",
    "    if bandDepth>1:\n",
    "        bandDepth=1\n",
    "    return bandCentre,bandDepth,polynomialReflectance,interpolatedWavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a half feature interpolate the feature to triple the number of points\n",
    "def interpolateLowerFeature(lowerWavelength,lowerRelfectance):\n",
    "    #get step size as 1/5 of the difference between consecutive bands\n",
    "    bandWidth=abs(lowerWavelength[0]-lowerWavelength[1])\n",
    "    stepSize=bandWidth/5\n",
    "    #generate list of interpolated wavelengths\n",
    "    interpolatedWavelengths=np.arange(lowerWavelength[0],lowerWavelength[-1],stepSize)\n",
    "    #fit a polynomial to the data\n",
    "    interpolator=interpolate.interp1d(lowerWavelength,lowerRelfectance,kind='cubic')\n",
    "    interpolatedReflectance=interpolator(interpolatedWavelengths)\n",
    "    return interpolatedWavelengths,interpolatedReflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate absorption peaks for all features\n",
    "def getFeatureParameters(wavelengths,reflectances):\n",
    "    #create empty lists to hold band centres,band depths,fwhm, and left & right shoulders\n",
    "    bandCentres=[]\n",
    "    bandDepths=[]\n",
    "    leftShoulders=[]\n",
    "    rightShoulders=[]\n",
    "    bandMinimas=[]\n",
    "    #iterate over each feature\n",
    "\n",
    "    for i in range(len(reflectances)):\n",
    "        currentWavelength=wavelengths[i]\n",
    "        currentReflectance=reflectances[i]\n",
    "        #interpolate the feature if not possible use the original feature\n",
    "        try:\n",
    "            currentWavelength,currentReflectance=interpolateLowerFeature(currentWavelength,currentReflectance)\n",
    "        except:\n",
    "            pass\n",
    "        #get lower half of the feature\n",
    "        #get band centre\n",
    "        bandCentre=currentWavelength[np.argmin(currentReflectance)]\n",
    "        #get band depth\n",
    "        bandDepth=np.max(currentReflectance)-currentReflectance[np.argmin(currentReflectance)]\n",
    "\n",
    "        #get parameters for polynomial fit\n",
    "        featureBandCentre,featureBandDepth,fittedReflectance,fittedWavelength=getAbsorbanceParametersPolynomial(currentWavelength,currentReflectance)\n",
    "\n",
    "\n",
    "        #append parameters\n",
    "        try:\n",
    "            bandCentres.append(featureBandCentre[0])\n",
    "        except:\n",
    "            bandCentres.append(featureBandCentre)\n",
    "        try:\n",
    "            bandDepths.append(featureBandDepth[0])\n",
    "        except:\n",
    "            bandDepths.append(featureBandDepth)\n",
    "        leftShoulders.append(wavelengths[i][0])\n",
    "        rightShoulders.append(wavelengths[i][-1])\n",
    "    #return featureBandCentre,featureBandDepth,fwhm,fittedReflectance,fittedWavelength,bandMinimas\n",
    "    return bandCentres,bandDepths,leftShoulders,rightShoulders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given lists corresponding to spectral parameters for n features of a sample spectra. Check, if the sample is a carbonate\n",
    "def checkForCarbonate(bandCentres,bandDepths,leftShoulders,rightShoulders):\n",
    "    #specify range of acceptable values\n",
    "    bandCentre23LowerLimit=2.285\n",
    "    bandCentre23UpperLimit=2.345\n",
    "    bandCentre25LowerLimit=2.485\n",
    "    bandCentre25UpperLimit=2.545\n",
    "    interBandGapLowerLimit=0.19\n",
    "    interBandGapUpperLimit=0.22\n",
    "    \n",
    "    #specify ideal band centre values for Fe and Mg carbonates\n",
    "    feFirstIdealBandCentre=2.33\n",
    "    feSecondIdealBandCentre=2.53\n",
    "    mgFirstIdealBandCentre=2.30\n",
    "    mgSecondIdealBandCentre=2.50\n",
    "    #specify ideal value for inter band gap\n",
    "    idealInterBandGap=0.20\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create a flag to check if the sample is carbonate\n",
    "    carbonateFlag=False\n",
    "    #variable to store index of 2.3 feature\n",
    "    firstCO3FeatureIndex=-1\n",
    "    #get no of features\n",
    "    noOfFeatures=len(bandCentres)\n",
    "    \n",
    "    #iterate over all features\n",
    "    for i in range(noOfFeatures):\n",
    "        if i<noOfFeatures-1 and bandCentres[i]<=bandCentre23UpperLimit and bandCentres[i]>=bandCentre23LowerLimit and bandCentres[i+1]<=bandCentre25UpperLimit and bandCentres[i+1]>=bandCentre25LowerLimit and abs(bandCentres[i]-bandCentres[i+1])<=interBandGapUpperLimit and abs(bandCentres[i]-bandCentres[i+1])>=interBandGapLowerLimit:\n",
    "            firstCO3FeatureIndex=i\n",
    "            carbonateFlag=True\n",
    "    \n",
    "    #if sample is carbonate classify as Iron/Calcium or Magnesium\n",
    "    if carbonateFlag:\n",
    "        #calculate distances from ideal Iron band centres\n",
    "        fe23Distance=abs(feFirstIdealBandCentre-bandCentres[firstCO3FeatureIndex])\n",
    "        fe25Distance=abs(feSecondIdealBandCentre-bandCentres[firstCO3FeatureIndex+1])\n",
    "        #record greater distance\n",
    "        feDistanceFromIdeal=max(fe23Distance,fe25Distance)\n",
    "        #calcualte distances from ideal Magnesium band centres\n",
    "        mg23Distance=abs(mgFirstIdealBandCentre-bandCentres[firstCO3FeatureIndex])\n",
    "        mg25Distance=abs(mgSecondIdealBandCentre-bandCentres[firstCO3FeatureIndex+1])\n",
    "        #record greater distance\n",
    "        mgDistanceFromIdeal=max(mg23Distance,mg25Distance)\n",
    "        #check which recorded distance is lesser, mark as that carbonate\n",
    "        if mgDistanceFromIdeal<feDistanceFromIdeal:\n",
    "            return 1 #flag for Mg carbonte\n",
    "        else:\n",
    "            return 2 #flag for Fe carbonte\n",
    "    return 0 #flag for non carboante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given lists corresponding to band centres, band depth and fwhms of all features in a spectra find  2.3 and 2.5 mircon feature for fe/CaCO3 check inter band gap between two and classify the sample as Fe/CaCO# or not\n",
    "def checkCarbonateAdaptive(bandCentres,bandDepths,fwhms,bandCentreThreshold,InterBandGapThreshold):\n",
    "    ##specify ideal band centre values for Fe and Mg carbonates\n",
    "    feFirstIdealBandCentre=2.33\n",
    "    feSecondIdealBandCentre=2.53\n",
    "    mgFirstIdealBandCentre=2.30\n",
    "    mgSecondIdealBandCentre=2.50\n",
    "    #specify ideal value for inter band gap\n",
    "    idealInterBandGap=0.20\n",
    "    \n",
    "    #specify range of acceptable values\n",
    "    bandCentre23LowerLimit=min(mgFirstIdealBandCentre,feFirstIdealBandCentre)-bandCentreThreshold\n",
    "    bandCentre23UpperLimit=max(mgFirstIdealBandCentre,feFirstIdealBandCentre)+bandCentreThreshold\n",
    "    bandCentre25LowerLimit=min(mgSecondIdealBandCentre,feSecondIdealBandCentre)-bandCentreThreshold\n",
    "    bandCentre25UpperLimit=max(mgSecondIdealBandCentre,feSecondIdealBandCentre)+bandCentreThreshold\n",
    "    interBandGapLowerLimit=idealInterBandGap-InterBandGapThreshold\n",
    "    interBandGapUpperLimit=idealInterBandGap+InterBandGapThreshold\n",
    "    \n",
    "    \n",
    "    #create a flag to check if the sample is carbonate\n",
    "    carbonateFlag=False\n",
    "    #variable to store index of 2.3 feature\n",
    "    firstCO3FeatureIndex=-1\n",
    "    #get no of features\n",
    "    noOfFeatures=len(fwhms)\n",
    "    \n",
    "    #iterate over all features\n",
    "    for i in range(noOfFeatures):\n",
    "        if i<noOfFeatures-1 and bandCentres[i]<=bandCentre23UpperLimit and bandCentres[i]>=bandCentre23LowerLimit and bandCentres[i+1]<=bandCentre25UpperLimit and bandCentres[i+1]>=bandCentre25LowerLimit and abs(bandCentres[i]-bandCentres[i+1])<=interBandGapUpperLimit and abs(bandCentres[i]-bandCentres[i+1])>=interBandGapLowerLimit:\n",
    "            firstCO3FeatureIndex=i\n",
    "            carbonateFlag=True\n",
    "    \n",
    "    #if sample is carbonate classify as Iron/Calcium or Magnesium\n",
    "    if carbonateFlag:\n",
    "        #calculate distances from ideal Iron band centres\n",
    "        fe23Distance=abs(feFirstIdealBandCentre-bandCentres[firstCO3FeatureIndex])\n",
    "        fe25Distance=abs(feSecondIdealBandCentre-bandCentres[firstCO3FeatureIndex+1])\n",
    "        #record greater distance\n",
    "        feDistanceFromIdeal=max(fe23Distance,fe25Distance)\n",
    "        #calcualte distances from ideal Magnesium band centres\n",
    "        mg23Distance=abs(mgFirstIdealBandCentre-bandCentres[firstCO3FeatureIndex])\n",
    "        mg25Distance=abs(mgSecondIdealBandCentre-bandCentres[firstCO3FeatureIndex+1])\n",
    "        #record greater distance\n",
    "        mgDistanceFromIdeal=max(mg23Distance,mg25Distance)\n",
    "        #check which recorded distance is lesser, mark as that carbonate\n",
    "        if mgDistanceFromIdeal<feDistanceFromIdeal:\n",
    "            return 1 #flag for Mg carbonte\n",
    "        else:\n",
    "            return 2 #flag for Fe carbonte\n",
    "    return 0 #flag for non carboante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given lists corresponding to band centres, band depth and fwhms of all features in a spectra find  1.4 and 1.9 mircon feature for phyllosilicates check and classify the sample as Phyllosilicate or not\n",
    "def checkPhyllosilicate(bandCentres,bandDepths,fwhms):\n",
    "    #specify acceptable ranges\n",
    "    bandCentre14LowerLimit=1.33\n",
    "    bandCentre14UpperLimit=1.44\n",
    "    bandCentre19LowerLimit=1.89\n",
    "    bandCentre19UpperLimit=1.96\n",
    "    fwhm14LowerLimit=0.019\n",
    "    fwhm14UpperLimit=0.263\n",
    "    fwhm19LowerLimit=0.02\n",
    "    fwhm19UpperLimit=0.15\n",
    "    # create variables to hold indices for relavent features\n",
    "    feature14Index=-1\n",
    "    feature19Index=-1\n",
    "    for i in range(len(bandCentres)):\n",
    "        #check for 1.9 micron feature\n",
    "        if bandCentres[i]<=bandCentre14UpperLimit and bandCentres[i]>=bandCentre14LowerLimit and fwhms[i]<=fwhm14UpperLimit and fwhms[i]>=fwhm14LowerLimit and feature14Index==-1:\n",
    "            print(\"First phyllo. feature at index: \"+str(i))\n",
    "            feature14Index=i\n",
    "        #check for 1.9 micron feature\n",
    "        elif bandCentres[i]<=bandCentre19UpperLimit and bandCentres[i]>=bandCentre19LowerLimit and fwhms[i]<=fwhm19UpperLimit and fwhms[i]>=fwhm19LowerLimit and feature19Index==-1:\n",
    "            print(\"First phyllo. feature at index: \"+str(i))\n",
    "            feature19Index=i\n",
    "    #check if both features found if so return True\n",
    "    if feature14Index>=0 and feature19Index>=0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a preprocessed and normalized spectra and its name process it and classify as Carbonate type or not carbonate\n",
    "def processSpectra(spectra):\n",
    "    spectra=normalizeSpectra(spectra)\n",
    "    cr=plotHull(spectra)\n",
    "    features,wavelengths=getAbsorptionFeatures(plotHull(spectra))\n",
    "    tempFeat=[]\n",
    "    tempWavelengths=[]\n",
    "    for i in range(len(wavelengths)):\n",
    "        if len(wavelengths[i])>7:\n",
    "            tempFeat.append(features[i])\n",
    "            tempWavelengths.append(wavelengths[i])\n",
    "    features=tempFeat\n",
    "    wavelengths=tempWavelengths\n",
    "    #get spectral paramerters\n",
    "    bandCentres,bandDepths,leftShoulders,rightShoulders=getFeatureParameters(wavelengths,features)\n",
    "    #remove any absorption features that have no band depth i.e. band depth==0\n",
    "    tempFeat=[]\n",
    "    tempWavelengths=[]\n",
    "    tempBandCentres=[]\n",
    "    tempBandDepths=[]\n",
    "    tempLeftShoulders=[]\n",
    "    tempRightShoulders=[]\n",
    "    for i in range(len(wavelengths)):\n",
    "        if bandDepths[i]>0.005:\n",
    "            tempFeat.append(features[i])\n",
    "            tempWavelengths.append(wavelengths[i])\n",
    "            tempBandCentres.append(bandCentres[i])\n",
    "            tempBandDepths.append(bandDepths[i])\n",
    "            tempLeftShoulders.append(leftShoulders[i])\n",
    "            tempRightShoulders.append(rightShoulders[i])\n",
    "    features=tempFeat\n",
    "    wavelengths=tempWavelengths\n",
    "    bandCentres=tempBandCentres\n",
    "    bandDepths=tempBandDepths\n",
    "    leftShoulders=tempLeftShoulders\n",
    "    rightShoulders=tempRightShoulders\n",
    "    #check if there are at least two absorption features if not return Not carbonate\n",
    "    if len(bandCentres)<2:\n",
    "        return 0\n",
    "    #check carbonate flag\n",
    "    co3Flag=checkForCarbonate(bandCentres,bandDepths,leftShoulders,rightShoulders)\n",
    "    if co3Flag==0:\n",
    "        #print(\"Not CO3\")\n",
    "        return 0\n",
    "    elif co3Flag==1:\n",
    "        #print(\"MgCO3\")\n",
    "        return 1\n",
    "    else:\n",
    "        #print(\"FeCO3\")\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulate mean reflectance at wavelength with defined kernel size for a single spectra\n",
    "def calculateReflectanceAtWavelengthForSpectra(wavelength,spectra,kernelSize):\n",
    "    global wavelengthList\n",
    "    targetWavelength=find_nearest(wavelengthList,wavelength) #find nearest wavelength value in list\n",
    "    targetWavelengthIndex=find_nearest_index(wavelengthList,wavelength) \n",
    "    reflectance=spectra[targetWavelengthIndex]\n",
    "    for i in range(targetWavelengthIndex-math.floor(kernelSize/2),targetWavelengthIndex+math.floor(kernelSize/2)):\n",
    "        reflectance=reflectance+spectra[i]\n",
    "    reflectance=reflectance-spectra[targetWavelengthIndex]\n",
    "    return reflectance/kernelSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate band depth based indices for Fe and Ca/Mg rich carbonates\n",
    "def calculateCarbonateBandDepthIndicesForSpectra(spectra):\n",
    "    global wavelengthList\n",
    "    R2345Wavelength=2.345 #define constant values to calculate indices, wavelengths, and kernel size \n",
    "    R2250Wavelength=2.250\n",
    "    R2430Wavelength=2.430\n",
    "    R2537Wavelength=2.537\n",
    "    R2602Wavelength=2.590#2.602\n",
    "\n",
    "    R2345KernelSize=5\n",
    "    R2250KernelSize=5\n",
    "    R2430KernelSize=5\n",
    "    R2602KernelSize=1\n",
    "    R2537KernelSize=5\n",
    "\n",
    "    R2295Wavelength=2.295\n",
    "    R2165Wavelength=2.165\n",
    "    R2364Wavelength=2.364\n",
    "    R2480Wavelength=2.480\n",
    "    R2570Wavelength=2.570\n",
    "\n",
    "    R2295KernelSize=5\n",
    "    R2165KernelSize=5\n",
    "    R2364KernelSize=5\n",
    "    R2480KernelSize=5\n",
    "    R2570KernelSize=5\n",
    "\n",
    "\n",
    "    bForR2430=(R2345Wavelength-R2250Wavelength)/(R2430Wavelength-R2250Wavelength)\n",
    "    aForR2250=1-bForR2430\n",
    "    bForR2602=(R2537Wavelength-R2430Wavelength)/(R2602Wavelength-R2430Wavelength)\n",
    "    aForR2430=1-bForR2602\n",
    "\n",
    "    bForR2364=(R2295Wavelength-R2165Wavelength)/(R2364Wavelength-R2165Wavelength)\n",
    "    aForR2165=1-bForR2364\n",
    "    bForR2570=(R2480Wavelength-R2364Wavelength)/(R2570Wavelength-R2364Wavelength)\n",
    "    aForR2364=1-bForR2570\n",
    "    \n",
    "    \n",
    "    R2295Reflectance=calculateReflectanceAtWavelengthForSpectra(R2295Wavelength,spectra,R2295KernelSize) #read bands corresponding to wavelengths\n",
    "    R2165Reflectance=calculateReflectanceAtWavelengthForSpectra(R2165Wavelength,spectra,R2165KernelSize)\n",
    "    R2364Reflectance=calculateReflectanceAtWavelengthForSpectra(R2364Wavelength,spectra,R2364KernelSize)\n",
    "    R2480Reflectance=calculateReflectanceAtWavelengthForSpectra(R2480Wavelength,spectra,R2480KernelSize)\n",
    "    R2570Reflectance=calculateReflectanceAtWavelengthForSpectra(R2570Wavelength,spectra,R2570KernelSize)\n",
    "\n",
    "    temp1Den=aForR2165*R2165Reflectance+bForR2364*R2364Reflectance # calculation for MIN2295_2480 minimum band depth at 2.3 and 2.5 micrometer \n",
    "    temp2Den=aForR2364*R2364Reflectance+bForR2570*R2570Reflectance\n",
    "    temp3=2\n",
    "    \n",
    "    temp1=R2295Reflectance/temp1Den\n",
    "    temp1=1-temp1\n",
    "    temp3=2\n",
    "    temp2=R2480Reflectance/temp2Den\n",
    "    temp2=1-temp2\n",
    "    MIN2295_2480=min(temp1,temp2)\n",
    "    \n",
    "    R2345Reflectance=calculateReflectanceAtWavelengthForSpectra(R2345Wavelength,spectra,R2345KernelSize) #read bands corresponding to wavelengths\n",
    "    R2250Reflectance=calculateReflectanceAtWavelengthForSpectra(R2250Wavelength,spectra,R2250KernelSize)\n",
    "    R2430Reflectance=calculateReflectanceAtWavelengthForSpectra(R2430Wavelength,spectra,R2430KernelSize)\n",
    "    R2537Reflectance=calculateReflectanceAtWavelengthForSpectra(R2537Wavelength,spectra,R2537KernelSize)\n",
    "    R2602Reflectance=calculateReflectanceAtWavelengthForSpectra(R2602Wavelength,spectra,R2602KernelSize)\n",
    "    \n",
    "    temp1Den=aForR2250*R2250Reflectance+bForR2430*R2430Reflectance # calculation for MIN2345_2537 minimum band depth at 2.33 and 2.53 micrometer\n",
    "    temp2Den=aForR2430*R2250Reflectance+bForR2602*R2602Reflectance\n",
    "    temp3=np.full_like(R2345Reflectance,2.0)\n",
    "    \n",
    "    temp1=R2345Reflectance/temp1Den\n",
    "    temp1=1-temp1\n",
    "    temp3=2.0\n",
    "    temp2=R2537Reflectance/temp2Den\n",
    "    temp2=1-temp2\n",
    "    MIN2345_2537=min(temp1,temp2)\n",
    "    \n",
    "    return MIN2295_2480,MIN2345_2537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the wavelength list of an atmospherically corrected C\n",
    "headerFileAddress=\"K:/Atmospherically Corrected CRISM images/frs00036f60_01_if169l_trr3_CAT_corr.hdr\"\n",
    "currentObservationHeader=envi.open(headerFileAddress)\n",
    "fullWavelengthList=np.asarray(currentObservationHeader.bands.centers)\n",
    "del currentObservationHeader\n",
    "#subset the wavlength list to the same range as the denosised samples\n",
    "lowerThresholdForSpectralSubset=1.0\n",
    "upperThresholdForSpectralSubset=2.62\n",
    "wavelengthList=fullWavelengthList[find_nearest_index(fullWavelengthList,lowerThresholdForSpectralSubset)+2:find_nearest_index(fullWavelengthList,upperThresholdForSpectralSubset)+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array to hold names of mineral end-members of labels\n",
    "labelNames=[\"CO2-Ice\",\"H2O-Ice\",\"Gypsum\",\"Ferric-hydroxysulphate\",\"Hematite\",\n",
    "            \"Fe-smectite\",\"Mg-smectite\",\"Prehnite\",\"Jarosite\",\"Serpentine\",\n",
    "            \"Alunite\",\"Akaganeite\",\"Ca/Fe-CO3\",\"Al-Smectite-1\",\"Kaolinite\",\n",
    "            \"Bassanite\",\"Epidote\",\"Al-smectite-2\",\"Polyhydrated-sulphate\",\"None\",\n",
    "            \"None\",\"None\",\"Illite\",\"None\",\"Analcime\",\n",
    "            \"Monohydrated-sulphate\",\"Hydrated-silica\",\"None\",\"Ferricopiapite\",\"Mg-CO3\",\n",
    "            \"Chlorite\",\"None\",\"Low-Calcium-Pyroxene\",\"Mg-Olivine\",\"High-Calcium-Pyroxene\",\n",
    "            \"Fe-Olivine\",\"Chloride\",\"2.1-m-artifact\",\"Bland\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the directory containing all the samples\n",
    "labelledDenoisedSamplesDirectory=\"K:/Martian Labelled Spectra\"\n",
    "#get list of all files in the directory\n",
    "allSampleFiles=os.listdir(labelledDenoisedSamplesDirectory)\n",
    "#create lists to hold spectra,original label, and predicted label, image, id of spectra and coordinates in image\n",
    "allActualLabels=[]\n",
    "allPredictedLabels=[]\n",
    "allSpectra=[]\n",
    "allSpectraIDs=[]\n",
    "allImageIDs=[]\n",
    "allXCoordinates=[]\n",
    "allYCoordinates=[]\n",
    "#iterate over all samples\n",
    "for i in range(len(allSampleFiles)):\n",
    "    #read the current file\n",
    "    currentCSVFileAddress=labelledDenoisedSamplesDirectory+\"/\"+allSampleFiles[i]\n",
    "    currentFile=open(currentCSVFileAddress)\n",
    "    currentCSVReader=csv.reader(currentFile)\n",
    "    #read the spectra from the CSV file\n",
    "    currentSpectrum=[]\n",
    "    for currentRow in currentCSVReader:\n",
    "        if len(currentRow)>0:\n",
    "            currentSpectrum=((np.asarray(currentRow)).astype(float))\n",
    "            break\n",
    "    currentFile.close()\n",
    "    #scale the spectrum\n",
    "    scaledSpectrum=normalizeSpectra(currentSpectrum)\n",
    "    #process the spectra i.e. check for carbonate\n",
    "    predictedLabel=-1\n",
    "    try:\n",
    "        predictedLabel=processSpectra(scaledSpectrum)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #get the ID of the spectra\n",
    "    sampleID=allSampleFiles[i][:allSampleFiles[i].index('_')]\n",
    "    #get the actual label\n",
    "    actualLabel=allSampleFiles[i][allSampleFiles[i].rindex('_')+1:allSampleFiles[i].index('.')]\n",
    "    #get the Image ID\n",
    "    imageID=allSampleFiles[i][allSampleFiles[i].index('_')+1:allSampleFiles[i].index('.')]\n",
    "    imageID=imageID[:imageID.index('_')]\n",
    "    #get the row number\n",
    "    rowNumber=allSampleFiles[i][allSampleFiles[i].index('_')+1:allSampleFiles[i].index('.')]\n",
    "    rowNumber=rowNumber[rowNumber.index('_')+1:]\n",
    "    rowNumber=rowNumber[:rowNumber.index('_')]\n",
    "    #get the column number\n",
    "    colNumber=allSampleFiles[i][allSampleFiles[i].index('_')+1:allSampleFiles[i].index('.')]\n",
    "    colNumber=colNumber[:colNumber.rindex('_')]\n",
    "    colNumber=colNumber[colNumber.rindex('_')+1:]\n",
    "    \n",
    "    #save the actual label \n",
    "    allActualLabels.append(actualLabel)\n",
    "    #save the predicted label to a list\n",
    "    allPredictedLabels.append(predictedLabel)\n",
    "    #save the spectrum\n",
    "    allSpectra.append(scaledSpectrum)\n",
    "    #save the ID of the sample\n",
    "    allSpectraIDs.append(sampleID)\n",
    "    #save the ID of the image from which the sample is taken\n",
    "    allImageIDs.append(imageID)\n",
    "    #save the number of the row from which the sample is taken\n",
    "    allXCoordinates.append(rowNumber)\n",
    "    #save the number of the column from which the sample is taken\n",
    "    allYCoordinates.append(colNumber)\n",
    "\n",
    "    if i%25000==0:\n",
    "        print(f\"{i}-Spectra processed. {i*100/len(allSampleFiles)}% Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
