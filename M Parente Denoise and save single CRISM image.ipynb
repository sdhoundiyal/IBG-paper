{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required package\n",
    "from __future__ import division\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import spectral.io.envi as envi\n",
    "from spectral import *\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import PIL\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "import traceback\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file mangement generates a list containing a pth to all hdr files of pre-processed observations\n",
    "def get_all_processed_HDR_addresses():\n",
    "    parentDirectory=\"G:/0000A546/\"\n",
    "    observationDirectories=[]\n",
    "    for (_,temporaryList,_) in os.walk(parentDirectory):\n",
    "        observationDirectories.extend(temporaryList)\n",
    "        break\n",
    "\n",
    "    hdrPattern=\".hdr$\"\n",
    "    ObservationImageAddresses=[]\n",
    "\n",
    "\n",
    "    for j in observationDirectories:\n",
    "        currentDirectory=parentDirectory+'/'+j\n",
    "        observationFiles=[]\n",
    "        for (_,_,temporaryList) in os.walk(currentDirectory):\n",
    "            observationFiles.extend(temporaryList)\n",
    "            break\n",
    "\n",
    "        for i in observationFiles:\n",
    "            if re.search(hdrPattern,i):\n",
    "                ObservationImageAddresses.append(currentDirectory+\"/\"+i[:i.index(\".hdr\")]+\"_corr_p.hdr\")\n",
    "    return ObservationImageAddresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read hrd files for wavlengths of all bands\n",
    "def read_CRISM_Image_wavelengths(headerFileAddress):\n",
    "    wavelengthFile=\"J:/IIT/user/Documents/CRISM Multispectral Exploration/Processed_observations/wavelength_list.txt\"\n",
    "    \n",
    "    currentObservationHeader=envi.open(headerFileAddress)\n",
    "    currentObservationImage=currentObservationHeader.open_memmap()\n",
    "    currentObservationArray=np.array(currentObservationImage)\n",
    "    #currentObservationArray=spectral.open_image(i)\n",
    "\n",
    "    #read wavelengths from saved wavelength file\n",
    "    with open (wavelengthFile, 'rb') as fp:\n",
    "        wavelengthsOfCurrentObservation=pickle.load(fp)\n",
    "    return currentObservationArray,wavelengthsOfCurrentObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find index of wavelngth closest to given wavelength\n",
    "def find_nearest(wavelength_list,value): #find wavelength value in list closest to given value\n",
    "    idx = np.searchsorted(wavelength_list, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(wavelength_list) or math.fabs(value - wavelength_list[idx-1]) < math.fabs(value - wavelength_list[idx])):\n",
    "        return wavelength_list[idx-1]\n",
    "    else:\n",
    "        return wavelength_list[idx]\n",
    "\n",
    "def find_wavelength_index(wavelength_list,item): #return index of in the array\n",
    "    first = 0\n",
    "    last = len(wavelength_list)-1\n",
    "    found = False\n",
    "    while( first<=last and not found):\n",
    "        mid = (first + last)//2\n",
    "        if wavelength_list[mid] == item :\n",
    "            found = True\n",
    "        else:\n",
    "            if item < wavelength_list[mid]:\n",
    "                last = mid - 1\n",
    "            else:\n",
    "                first = mid + 1\t\n",
    "    return mid\n",
    "def find_nearest_index(wavelength_list,wavelength): #get wavelength in index closest to gicen wavelength and return its index\n",
    "    (nearest_index,nearest_wavelength)=min(enumerate(wavelength_list), key=lambda x: abs(x[1]-wavelength))\n",
    "    return nearest_index\n",
    "def find_nearest_index_for_list(wavelength_list,wavelengths): # find index of nearest value for a list of given values\n",
    "    indices=[]\n",
    "    for i in wavelengths:\n",
    "        indices.append(find_nearest_index(wavelength_list,i))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a hyperspectral datacube and wavelengths to serve as upper and lower thresholds subset the datacube along the spectral direction\n",
    "def get_spectral_subset(datacube,wavelength_list,lower_threshold,upper_threshold): #returns spectral subset from lower to upper threshold ( 1.2 to 2.6 micrometer for CRISM IR)\n",
    "    lower_threshold_index=find_wavelength_index(wavelength_list,lower_threshold)\n",
    "    upper_threshold_index=find_wavelength_index(wavelength_list,upper_threshold)\n",
    "    thresholdedDatacube=datacube[:,:,lower_threshold_index:upper_threshold_index+1]\n",
    "    thresholdedWavelengthList=wavelength_list[lower_threshold_index:upper_threshold_index+1]\n",
    "    return thresholdedDatacube,thresholdedWavelengthList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold image at 2.6 micrometer\n",
    "def preProcessImage(imageHeaderAddress): # given address of a CRISM header file, read the data, deal with NaN values and apply spectral subset\n",
    "    datacube,wavelength_list=read_CRISM_Image_wavelengths(imageHeaderAddress) #read image and wavelength_list\n",
    "    datacube=np.where(np.logical_and(datacube>0,datacube<1),datacube,0)\n",
    "    lower_threshold_for_spectral_subset=1.0\n",
    "    upper_threshold_for_spectral_subset=2.59 #define wavelength threshold (CRISM data too noisy post 2.6 micrometer)\n",
    "    datacube,wavelength_list=get_spectral_subset(datacube,wavelength_list,lower_threshold_for_spectral_subset,upper_threshold_for_spectral_subset)\n",
    "    return datacube,wavelength_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the datacube and maximum possible size for the fliter implement and adaptive median filter that filters images in the across-track and spectral directions\n",
    "# https://github.com/mortezamg63/Adaptive-Median-Filter\n",
    "def adaptiveMedianFilter(maximumFilterSize):\n",
    "    global datacube\n",
    "    minimumFilterSize=7\n",
    "    edgeJustification=math.ceil((maximumFilterSize-1)/2)\n",
    "    datacube=np.pad(datacube,((edgeJustification,edgeJustification),(edgeJustification,edgeJustification),(edgeJustification,edgeJustification)),'symmetric') #pad the array symetrically to allow the maximum possible filter size to work\n",
    "    [row,col,bands]=np.shape(datacube)\n",
    "    filteredDatacube=np.zeros_like(datacube) # an array to store filtered datacube\n",
    "    for j in range(edgeJustification,col-edgeJustification):\n",
    "        for i in range(edgeJustification,row-edgeJustification):\n",
    "            for k in range(edgeJustification,bands-edgeJustification):\n",
    "                if datacube[i,j,k]>0 and datacube[i,j,k]<1:\n",
    "                    filteredDatacube[i,j,k]=findPixelMedian(minimumFilterSize,maximumFilterSize,i,j,k)\n",
    "        if (i-edgeJustification)%80==0:\n",
    "            print(f\"Row ---{(i-edgeJustification)}--- of --- 800 --- processed of col --- {(j-edgeJustification)} --- of --- 831 --- processed\")\n",
    "    datacube=filteredDatacube[edgeJustification:row-edgeJustification,edgeJustification:col-edgeJustification,edgeJustification:bands-edgeJustification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive function to compute adaptive median for a pixel\n",
    "def findPixelMedian(filterSize,maximumFilterSize,pixelRow,pixelCol,pixelBand):\n",
    "    global datacube\n",
    "    [row,col,bands]=np.shape(datacube)\n",
    "    edgeJustification=math.ceil((filterSize-1)/2)\n",
    "    pixelNeighbourhood=datacube[(pixelRow-edgeJustification):(pixelRow+edgeJustification),pixelCol,(pixelBand-edgeJustification):(pixelBand+edgeJustification)]\n",
    "    sortedNeighbourhood=np.sort(pixelNeighbourhood,axis=None)\n",
    "    valueMinimum=sortedNeighbourhood[0];\n",
    "    valueMaximum=sortedNeighbourhood[-1];\n",
    "    valueMedian=np.median(sortedNeighbourhood);\n",
    "    valueOriginal=datacube[pixelRow,pixelCol,pixelBand];\n",
    "    B1=valueOriginal-valueMinimum;\n",
    "    B2=valueOriginal-valueMaximum;\n",
    "    if B1>0 and B2<0:\n",
    "        return valueOriginal\n",
    "    else:\n",
    "        A1=valueMedian-valueMinimum\n",
    "        A2=valueMedian-valueMaximum\n",
    "        if A1>0 and A2<0:\n",
    "            return valueMedian\n",
    "        else:\n",
    "            if filterSize<maximumFilterSize:\n",
    "                filterSize=filterSize+2;\n",
    "                return findPixelMedian(filterSize,maximumFilterSize,pixelRow,pixelCol,pixelBand)\n",
    "            else:\n",
    "                return valueMedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denoising routine by M. Parente Vertical stripe removal implemented here\n",
    "def destripeCRISM():\n",
    "    global datacube\n",
    "    adaptiveMedianFilter(maximumFilterSize=30)# an adaptive median filter in across-track and spectral direction\n",
    "    datacube=ndimage.median_filter(datacube,footprint=np.ones((3,1,3)),mode='reflect') #median filter in across-track and spectral direction\n",
    "    #datacube=ndimage.gaussian_filter(datacube,sigma=(3,1,3),mode='reflect') #gaussian filter in across-track and spectral direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a spectra return its histogram [edges of histogram][frequency of each interval]\n",
    "def getSpectralHistogram(spectra):\n",
    "    bins=50 # number of bins for the histogram\n",
    "    histogram = np.histogram(spectra,bins) # given the spectra and number of bins calculate the histogram\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a subset of a (differnece) spectra apply Otsu's algorithm and return the threshold\n",
    "# adapted from https://github.com/bornreddy/smart-thresholds/blob/master/otsu.py\n",
    "def otsuSpectral(spectralSlice):\n",
    "    histogram=getSpectralHistogram(spectralSlice) #get histogram of the spectral slice\n",
    "    totalPoints=np.shape(spectralSlice[0]) # total number of points\n",
    "    maximumValue=0\n",
    "    threshold=0\n",
    "    sumT=0\n",
    "    sumF=0\n",
    "    sumB=0\n",
    "    for i in range(np.shape(histogram)[0]):\n",
    "        sumT=sumT+histogram[1][i]*histogram[0][i]\n",
    "    weightB=0\n",
    "    weightF=0\n",
    "    varianceBetween=0\n",
    "    meanB=0\n",
    "    meanF=0\n",
    "    for i in range(np.shape(histogram)[0]):\n",
    "        weightB=weightB+histogram[0][i]\n",
    "        weightF=totalPoints-weightB\n",
    "        if weightF==0:\n",
    "            break\n",
    "        sumB=sumB+histogram[1][i]*histogram[0][i]\n",
    "        sumF=sumT-sumB\n",
    "        meanB=sumB/weightB\n",
    "        meanF=sumF/weightF\n",
    "        varianceBetween=weightB*weightF\n",
    "        varianceBetween=varianceBetween*(meanB-meanF)*(meanB-meanF)\n",
    "        if varianceBetween>maximumValue:\n",
    "            maximumValue=varianceBetween\n",
    "            threhold=histogram[1][i]\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising routine by M. Parente Bad Pixel Spiking detection detected here\n",
    "# spikes are detected by applying Otsu's thresholding algorithm locally to classify difference between images as spike or non spike\n",
    "def despikeDatacube():\n",
    "    global datacube\n",
    "    [row,col,bands]=np.shape(datacube)\n",
    "    filterSize=int(math.floor(bands/10)) # size of filter to extract neighbourhood around a point from the spectra\n",
    "    if filterSize%2==0:\n",
    "        filterSize=filterSize+1\n",
    "    edgeJustification=math.ceil((filterSize-1)/2) # size to pad the array with to on both ends in the spectral directions\n",
    "    \n",
    "    differenceCube=np.zeros_like(datacube) # a 3d array to mark which pixels have spikes\n",
    "    for i in range(0,bands-1):\n",
    "        differenceCube[:,:,i]=datacube[:,:,i]-datacube[:,:,i+1] #calculate bandwise difference in reflectance\n",
    "    differenceCube=np.pad(differenceCube,((edgeJustification,edgeJustification),(edgeJustification,edgeJustification),(edgeJustification,edgeJustification)),'symmetric') # pad the difference cube in the spectral direction\n",
    "    badPixelFlagcube=np.zeros_like(datacube)\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            for k in range(edgeJustification,bands-edgeJustification):\n",
    "                threshold=otsuSpectral(differenceCube[i,j,k-edgeJustification:k+edgeJustification]) # get Otsu's threshold for the current pixel  \n",
    "                if differenceCube[i,j,k]>threshold: \n",
    "                    badPixelFlagcube[i-edgeJustification,j-edgeJustification,k-edgeJustification]=1 # if pixelvalue is more than threshold flag it as noisy pixel\n",
    "    despikedDatacube=np.zeros_like(datacube)\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            for k in range(bands):\n",
    "                if datacube[i,j,k]>0 and datacube[i,j,k]<1 and badPixelFlagcube[i,j,k]==1:\n",
    "                    despikedDatacube[i,j,k]=(datacube[i,j,k-1]+datacube[i,j,k+1])/2\n",
    "                else:\n",
    "                    despikedDatacube[i,j,k]=datacube[i,j,k]\n",
    "    datacube=despikedDatacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a datacube return its footprint i.e pixels in and out of the scene\n",
    "def getDatacubeFootprint(datacube):\n",
    "    [row,col,bands]=np.shape(datacube)\n",
    "    #create an array to hold footprint of the image\n",
    "    footprint=np.zeros_like(datacube[:,:,0])\n",
    "    #get foot print of in scene pixels\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if 0==datacube[i,j,:].all():\n",
    "                footprint[i,j]=1\n",
    "    return footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a spectra normalize it to the range (0,1)\n",
    "def normalizeSpectra(spectra):\n",
    "    return (spectra - np.min(spectra))/np.ptp(spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a datacube normalize all spectra\n",
    "def normalizeDatacube(datacube):\n",
    "    #get dimensions\n",
    "    [row,col,bands]=datacube.shape\n",
    "    #iterate through pixels\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            datacube[i,j,:]=normalizeSpectra(datacube[i,j,:])\n",
    "    return datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a datacube normalized each pixel and compute average spectra for each column\n",
    "def getColumnAdjustedDatcube(initialDatacube):\n",
    "    #normalize the datacube\n",
    "    initalDatacube=normalizeDatacube(initialDatacube)\n",
    "    [row,col,bands]=np.shape(initalDatacube)\n",
    "    #get footprint\n",
    "    footprint=getDatacubeFootprint(initialDatacube)\n",
    "    #calculate column sum spectra\n",
    "    columnSpectra=np.sum(initalDatacube,axis=0)\n",
    "    #calculate number of inscene pixels in each column\n",
    "    inScenePixels=np.sum(footprint,axis=0)\n",
    "    #get the average column spectra\n",
    "    avgColumnSpectra=np.zeros_like(columnSpectra)\n",
    "    for i in range(col):\n",
    "        avgColumnSpectra[i,:]=columnSpectra[i,:]/inScenePixels[i]\n",
    "    #create a datacube to hold the average spectra\n",
    "    processedDatacube=np.zeros_like(initialDatacube)\n",
    "    #iterate through datacube and divide each pixel by its avgcolumn spectra\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            processedDatacube[i,j,:]=np.divide(initialDatacube[i,j,:],avgColumnSpectra[j,:])\n",
    "    #normalize the datacube\n",
    "    processedDatacube=normalizeDatacube(initialDatacube)\n",
    "    processedDatacube=np.where(np.logical_and(processedDatacube<1,processedDatacube>0),processedDatacube,0)\n",
    "    return processedDatacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given an array the trasnform and projection and the address write the array to that address\n",
    "def saveGeoRefrencedOutput(outputData,outputTransform,outputProjection,outputFileAddress,dataType):\n",
    "    #get dimensions of the data\n",
    "    [outputBands,outputCols,outputRows]=outputData.shape\n",
    "    #create an envi driver\n",
    "    enviDriver=gdal.GetDriverByName(\"ENVI\")\n",
    "    #create a place for the output\n",
    "    outputFile=enviDriver.Create(outputFileAddress,outputRows,outputCols,outputBands,dataType)\n",
    "    #apply transform\n",
    "    outputFile.SetGeoTransform(outputTransform)\n",
    "    #apply projection\n",
    "    outputFile.SetProjection(outputProjection)\n",
    "    #get band to write data in and write data into it\n",
    "    for i in range(1,outputBands+1):\n",
    "        #get band\n",
    "        outputBand=outputFile.GetRasterBand(i)\n",
    "        #write data to band\n",
    "        outputBand.WriteArray(outputData[i-1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(i):\n",
    "    #get img file address\n",
    "    imageAddress=i[:i.rindex('/')]\n",
    "    imageName=imageAddress[imageAddress.rindex('/')+1:]\n",
    "    #get datacube and wavelength list\n",
    "    ogDatacube,wavelengthList=preProcessImage(i)\n",
    "    #divide each pixel by the average of its column\n",
    "    colAdjustedDatacube=getColumnAdjustedDatcube(ogDatacube)\n",
    "    global datacube\n",
    "    datacube=colAdjustedDatacube\n",
    "    #destripe the datacube\n",
    "    destripeCRISM()\n",
    "    destripedDatacube=datacube\n",
    "    #despike the datacube\n",
    "    despikeDatacube()\n",
    "    despikedDatacube=datacube\n",
    "    #use gdal to get the image's transform and projection\n",
    "    #open the img file\n",
    "    imageFile=gdal.Open(i[:i.rindex('.')]+'.img')\n",
    "    #get  transform for both\n",
    "    transform=imageFile.GetGeoTransform()\n",
    "    #get projection for both \n",
    "    projection=imageFile.GetProjection()\n",
    "    #get datatype for each image both are same so get only 1\n",
    "    dataType=imageFile.GetRasterBand(1).DataType\n",
    "    '''\n",
    "    #rotate the datacube to GDAl standard\n",
    "    outputData=np.transpose(despikedDatacube)\n",
    "    outputData=np.rot90(outputData,axes=(1,2),k=3)\n",
    "    outputData=np.flip(outputData, axis=2)\n",
    "    \n",
    "    '''\n",
    "    #create file address\n",
    "    global processedImageDirectory\n",
    "    \n",
    "    return despikedDatacube \n",
    "    #saveGeoRefrencedOutput(outputData,transform,projection,outputFileAddress,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory where files are to be saved\n",
    "processedImageDirectory=\"G:/00005c5e\"\n",
    "#set the address of the file to be denoised\n",
    "inputImageAddress=\"G:/00005c5e/frt00005c5e_07_if166l_trr3_CAT_corr.img\"\n",
    "#open the img file\n",
    "imageFile=gdal.Open(inputImageAddress)\n",
    "#get  transform for both\n",
    "transform=imageFile.GetGeoTransform()\n",
    "#get projection for both \n",
    "projection=imageFile.GetProjection()\n",
    "#get datatype for each image both are same so get only 1\n",
    "dataType=imageFile.GetRasterBand(1).DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the datacube as an array\n",
    "datacube=imageFile.ReadAsArray()\n",
    "print(datacube.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerFileAddress=\"G:/00005c5e/frt00005c5e_07_if166l_trr3_CAT_corr.hdr\"\n",
    "currentObservationHeader=envi.open(headerFileAddress)\n",
    "wavelengthList=np.array(currentObservationHeader.bands.centers)\n",
    "wavelengthList=[1.001350, 1.007900, 1.014450, 1.021000, 1.027550, 1.034100, 1.040650,\n",
    " 1.047200, 1.053750, 1.060300, 1.066850, 1.073410, 1.079960, 1.086510,\n",
    " 1.093070, 1.099620, 1.106170, 1.112730, 1.119280, 1.125840, 1.132390,\n",
    " 1.138950, 1.145510, 1.152060, 1.158620, 1.165180, 1.171730, 1.178290,\n",
    " 1.184850, 1.191410, 1.197970, 1.204530, 1.211090, 1.217650, 1.224210,\n",
    " 1.230770, 1.237330, 1.243890, 1.250450, 1.257010, 1.263570, 1.270140,\n",
    " 1.276700, 1.283260, 1.289830, 1.296390, 1.302950, 1.309520, 1.316080,\n",
    " 1.322650, 1.329210, 1.335780, 1.342340, 1.348910, 1.355480, 1.362050,\n",
    " 1.368610, 1.375180, 1.381750, 1.388320, 1.394890, 1.401450, 1.408020,\n",
    " 1.414590, 1.421160, 1.427730, 1.434310, 1.440880, 1.447450, 1.454020,\n",
    " 1.460590, 1.467160, 1.473740, 1.480310, 1.486880, 1.493460, 1.500030,\n",
    " 1.506610, 1.513180, 1.519760, 1.526330, 1.532910, 1.539480, 1.546060,\n",
    " 1.552640, 1.559210, 1.565790, 1.572370, 1.578950, 1.585520, 1.592100,\n",
    " 1.598680, 1.605260, 1.611840, 1.618420, 1.625000, 1.631580, 1.638160,\n",
    " 1.644740, 1.651330, 1.657910, 1.664490, 1.671070, 1.677660, 1.684240,\n",
    " 1.690820, 1.697410, 1.703990, 1.710580, 1.717160, 1.723750, 1.730330,\n",
    " 1.736920, 1.743510, 1.750090, 1.756680, 1.763270, 1.769850, 1.776440,\n",
    " 1.783030, 1.789620, 1.796210, 1.802800, 1.809390, 1.815980, 1.822570,\n",
    " 1.829160, 1.835750, 1.842340, 1.848930, 1.855520, 1.862120, 1.868710,\n",
    " 1.875300, 1.881900, 1.888490, 1.895080, 1.901680, 1.908270, 1.914870,\n",
    " 1.921460, 1.928060, 1.934650, 1.941250, 1.947850, 1.954440, 1.961040,\n",
    " 1.967640, 1.974240, 1.980840, 1.987430, 1.994030, 2.000630, 2.007230,\n",
    " 2.013830, 2.020430, 2.027030, 2.033630, 2.040240, 2.046840, 2.053440,\n",
    " 2.060040, 2.066640, 2.073250, 2.079850, 2.086450, 2.093060, 2.099660,\n",
    " 2.106270, 2.112870, 2.119480, 2.126080, 2.132690, 2.139300, 2.145900,\n",
    " 2.152510, 2.159120, 2.165720, 2.172330, 2.178940, 2.185550, 2.192160,\n",
    " 2.198770, 2.205380, 2.211990, 2.218600, 2.225210, 2.231820, 2.238430,\n",
    " 2.245040, 2.251650, 2.258270, 2.264880, 2.271490, 2.278100, 2.284720,\n",
    " 2.291330, 2.297950, 2.304560, 2.311180, 2.317790, 2.324410, 2.331020,\n",
    " 2.337640, 2.344260, 2.350870, 2.357490, 2.364110, 2.370720, 2.377340,\n",
    " 2.383960, 2.390580, 2.397200, 2.403820, 2.410440, 2.417060, 2.423680,\n",
    " 2.430300, 2.436920, 2.443540, 2.450170, 2.456790, 2.463410, 2.470030,\n",
    " 2.476660, 2.483280, 2.489900, 2.496530, 2.503120, 2.509720, 2.516320,\n",
    " 2.522920, 2.529510, 2.536110, 2.542710, 2.549310, 2.555910, 2.562510,\n",
    " 2.569110, 2.575710, 2.582310, 2.588910, 2.595510, 2.602120, 2.608720,\n",
    " 2.615320, 2.621920, 2.628530, 2.635130, 2.641740, 2.648340, 2.654950,\n",
    " 2.661550, 2.668160, 2.674760, 2.681370, 2.687980, 2.694580, 2.701190,\n",
    " 2.760680, 2.767290, 2.773900, 2.780520, 2.787130, 2.793740, 2.800350,\n",
    " 2.806970, 2.813580, 2.820200, 2.826810, 2.833430, 2.840040, 2.846660,\n",
    " 2.853280, 2.859890, 2.866510, 2.873130, 2.879750, 2.886360, 2.892980,\n",
    " 2.899600, 2.906220, 2.912840, 2.919460, 2.926080, 2.932700, 2.939320,\n",
    " 2.945950, 2.952570, 2.959190, 2.965810, 2.972440, 2.979060, 2.985680,\n",
    " 2.992310, 2.998930, 3.005560, 3.012180, 3.018810, 3.025440, 3.032060,\n",
    " 3.038690, 3.045320, 3.051950, 3.058570, 3.065200, 3.071830, 3.078460,\n",
    " 3.085090, 3.091720, 3.098350, 3.104980, 3.111610, 3.118250, 3.124880,\n",
    " 3.131510, 3.138140, 3.144780, 3.151410, 3.158040, 3.164680, 3.171310,\n",
    " 3.177950, 3.184580, 3.191220, 3.197850, 3.204490, 3.211130, 3.217760,\n",
    " 3.224400, 3.231040, 3.237680, 3.244320, 3.250960, 3.257600, 3.264240,\n",
    " 3.270880, 3.277520, 3.284160, 3.290800, 3.297440, 3.304080, 3.310730,\n",
    " 3.317370, 3.324010, 3.330660, 3.337300, 3.343950, 3.350590, 3.357240,\n",
    " 3.363880, 3.370530, 3.377170, 3.383820, 3.390470, 3.397120, 3.403760,\n",
    " 3.410410, 3.417060, 3.423710, 3.430360, 3.437010, 3.443660, 3.450310,\n",
    " 3.456960, 3.463610, 3.470260, 3.476920, 3.483570, 3.490220, 3.496870,\n",
    " 3.503530, 3.510180, 3.516840, 3.523490, 3.530150, 3.536800, 3.543460,\n",
    " 3.550110, 3.556770, 3.563430, 3.570080, 3.576740, 3.583400, 3.590060,\n",
    " 3.596720, 3.603380, 3.610040, 3.616700, 3.623360, 3.630020, 3.636680,\n",
    " 3.643340, 3.650000, 3.656670, 3.663330, 3.669990, 3.676650, 3.683320,\n",
    " 3.689980, 3.696650, 3.703310, 3.709980, 3.716640, 3.723310, 3.729980,\n",
    " 3.736640, 3.743310, 3.749980, 3.756650, 3.763310, 3.769980, 3.776650,\n",
    " 3.783320, 3.789990, 3.796660, 3.803330, 3.810000, 3.816670, 3.823350,\n",
    " 3.830020, 3.836690, 3.843360, 3.850040, 3.856710, 3.863390, 3.870060,\n",
    " 3.876730, 3.883410, 3.890080, 3.896760, 3.903440, 3.910110, 3.916790,\n",
    " 3.923470, 3.930150, 3.936820, 4.000000]\n",
    "\n",
    "wavelengthList=np.array(wavelengthList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the wavelength of the last band to retain\n",
    "finalBandWavelength=2.628530\n",
    "#subset the datacube and wavelength list at the final wavelength\n",
    "#datacube=datacube[np.logical_and(wavelengthList<=2.68798,wavelengthList>=1.05375),:,:]\n",
    "wavelengthList=wavelengthList[np.logical_and(wavelengthList<=2.68798,wavelengthList>=1.05375)]\n",
    "#reorder the axis of the datacube from band,row,column to row,column,band\n",
    "datacube=np.moveaxis(datacube,0,-1)\n",
    "#set all nan values (65535) to np.nan\n",
    "#datacube[datacube==65535.0]=np.nan\n",
    "#remove variable no longer in use\n",
    "del finalBandWavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get indices of all non-NaN pixels and sort the row and column values\n",
    "nonNaNRows,nonNaNCols=np.where(~np.isnan(datacube[:,:,0]))\n",
    "nonNaNRows.sort()\n",
    "nonNaNCols.sort()\n",
    "#get the row and col ranges of the non-NaN pixels in the image\n",
    "rowLowerBound=nonNaNRows[0]\n",
    "rowUpperBound=nonNaNRows[-1]\n",
    "colLowerBound=nonNaNCols[0]\n",
    "colUpperBound=nonNaNCols[-1]\n",
    "del nonNaNRows\n",
    "del nonNaNCols\n",
    "#subset the datacube to just the non-NaN pixels\n",
    "datacube=datacube[rowLowerBound:rowUpperBound,colLowerBound:colUpperBound,:]\n",
    "#save the og datacube \n",
    "ogDatacube=datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rowLowerBound)\n",
    "print(rowUpperBound)\n",
    "print(colLowerBound)\n",
    "print(colUpperBound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide each pixel by the average of its column\n",
    "colAdjustedDatacube=getColumnAdjustedDatcube(datacube)\n",
    "datacube=colAdjustedDatacube\n",
    "#destripe the datacube\n",
    "destripeCRISM()\n",
    "destripedDatacube=datacube\n",
    "#despike the datacube\n",
    "despikeDatacube()\n",
    "despikedDatacube=datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destripedDatacube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#create a 3X3X3 structuring element\n",
    "structingElementSize=5\n",
    "structuringElement=np.full((structingElementSize,structingElementSize,structingElementSize), 1.0/structingElementSize**3)\n",
    "#apply mean filter to the datacube using the structuring element\n",
    "filteredDatacube=ndimage.filters.convolve(despikedDatacube,structuringElement,output=None,mode='reflect')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rowNo=50\n",
    "colNo=45\n",
    "startBand=3\n",
    "endBand=-9\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.plot(wavelengthList[startBand:endBand],normalizeSpectra(datacube[rowNo,colNo,startBand:endBand]),lw=5)\n",
    "plt.plot(wavelengthList[startBand:endBand],normalizeSpectra(despikedDatacube[rowNo,colNo,startBand:endBand]),lw=5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the band numbers to make the FCC\n",
    "FCCBands=[13,78,233]\n",
    "#create FCC stack\n",
    "FCCStack=despikedDatacube[:,:,FCCBands]\n",
    "#apply a 2% stretch\n",
    "quantileValues=[]\n",
    "for i in range(FCCStack.shape[2]):\n",
    "    #get the quantiles 2% and 98%\n",
    "    quantileValues=np.quantile(FCCStack[:,:,i],[0.02,0.98])\n",
    "    #save band to a temporary variable\n",
    "    temp=FCCStack[:,:,i]\n",
    "    #set values outside the quantile range to the edge values\n",
    "    temp[temp<quantileValues[0]]=quantileValues[0]\n",
    "    temp[temp>quantileValues[1]]=quantileValues[1]\n",
    "    #scale the values to the range\n",
    "    temp=(temp-np.min(temp))/np.ptp(temp)\n",
    "    #save the processed band\n",
    "    FCCStack[:,:,i]=temp\n",
    "del temp\n",
    "#display the FCC\n",
    "baseFigureSize=10\n",
    "plt.figure(figsize=(baseFigureSize*FCCStack.shape[1]/FCCStack.shape[0],baseFigureSize))\n",
    "plt.imshow(FCCStack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the band numbers to make the FCC\n",
    "FCCBands=[13,78,233]\n",
    "#create FCC stack\n",
    "FCCStack=datacube[:,:,FCCBands]\n",
    "#apply a 2% stretch\n",
    "quantileValues=[]\n",
    "for i in range(FCCStack.shape[2]):\n",
    "    #get the quantiles 2% and 98%\n",
    "    quantileValues=np.quantile(FCCStack[:,:,i],[0.02,0.98])\n",
    "    #save band to a temporary variable\n",
    "    temp=FCCStack[:,:,i]\n",
    "    #set values outside the quantile range to the edge values\n",
    "    temp[temp<quantileValues[0]]=quantileValues[0]\n",
    "    temp[temp>quantileValues[1]]=quantileValues[1]\n",
    "    #scale the values to the range\n",
    "    temp=(temp-np.min(temp))/np.ptp(temp)\n",
    "    #save the processed band\n",
    "    FCCStack[:,:,i]=temp\n",
    "del temp\n",
    "#display the FCC\n",
    "baseFigureSize=10\n",
    "plt.figure(figsize=(baseFigureSize*FCCStack.shape[1]/FCCStack.shape[0],baseFigureSize))\n",
    "plt.imshow(FCCStack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the address of the file where the denoised image is to be saved\n",
    "inputImageAddress=\"G:/00005c5e/frt00005c5e_07_if166l_trr3_CAT_corr_denoising.img\"\n",
    "#open the img file\n",
    "imageFile=gdal.Open(inputImageAddress)\n",
    "#read the datacube from the destination file\n",
    "destinationDatacube=imageFile.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinationDatacube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogWavelengthList=[1.001350, 1.007900, 1.014450, 1.021000, 1.027550, 1.034100, 1.040650,\n",
    " 1.047200, 1.053750, 1.060300, 1.066850, 1.073410, 1.079960, 1.086510,\n",
    " 1.093070, 1.099620, 1.106170, 1.112730, 1.119280, 1.125840, 1.132390,\n",
    " 1.138950, 1.145510, 1.152060, 1.158620, 1.165180, 1.171730, 1.178290,\n",
    " 1.184850, 1.191410, 1.197970, 1.204530, 1.211090, 1.217650, 1.224210,\n",
    " 1.230770, 1.237330, 1.243890, 1.250450, 1.257010, 1.263570, 1.270140,\n",
    " 1.276700, 1.283260, 1.289830, 1.296390, 1.302950, 1.309520, 1.316080,\n",
    " 1.322650, 1.329210, 1.335780, 1.342340, 1.348910, 1.355480, 1.362050,\n",
    " 1.368610, 1.375180, 1.381750, 1.388320, 1.394890, 1.401450, 1.408020,\n",
    " 1.414590, 1.421160, 1.427730, 1.434310, 1.440880, 1.447450, 1.454020,\n",
    " 1.460590, 1.467160, 1.473740, 1.480310, 1.486880, 1.493460, 1.500030,\n",
    " 1.506610, 1.513180, 1.519760, 1.526330, 1.532910, 1.539480, 1.546060,\n",
    " 1.552640, 1.559210, 1.565790, 1.572370, 1.578950, 1.585520, 1.592100,\n",
    " 1.598680, 1.605260, 1.611840, 1.618420, 1.625000, 1.631580, 1.638160,\n",
    " 1.644740, 1.651330, 1.657910, 1.664490, 1.671070, 1.677660, 1.684240,\n",
    " 1.690820, 1.697410, 1.703990, 1.710580, 1.717160, 1.723750, 1.730330,\n",
    " 1.736920, 1.743510, 1.750090, 1.756680, 1.763270, 1.769850, 1.776440,\n",
    " 1.783030, 1.789620, 1.796210, 1.802800, 1.809390, 1.815980, 1.822570,\n",
    " 1.829160, 1.835750, 1.842340, 1.848930, 1.855520, 1.862120, 1.868710,\n",
    " 1.875300, 1.881900, 1.888490, 1.895080, 1.901680, 1.908270, 1.914870,\n",
    " 1.921460, 1.928060, 1.934650, 1.941250, 1.947850, 1.954440, 1.961040,\n",
    " 1.967640, 1.974240, 1.980840, 1.987430, 1.994030, 2.000630, 2.007230,\n",
    " 2.013830, 2.020430, 2.027030, 2.033630, 2.040240, 2.046840, 2.053440,\n",
    " 2.060040, 2.066640, 2.073250, 2.079850, 2.086450, 2.093060, 2.099660,\n",
    " 2.106270, 2.112870, 2.119480, 2.126080, 2.132690, 2.139300, 2.145900,\n",
    " 2.152510, 2.159120, 2.165720, 2.172330, 2.178940, 2.185550, 2.192160,\n",
    " 2.198770, 2.205380, 2.211990, 2.218600, 2.225210, 2.231820, 2.238430,\n",
    " 2.245040, 2.251650, 2.258270, 2.264880, 2.271490, 2.278100, 2.284720,\n",
    " 2.291330, 2.297950, 2.304560, 2.311180, 2.317790, 2.324410, 2.331020,\n",
    " 2.337640, 2.344260, 2.350870, 2.357490, 2.364110, 2.370720, 2.377340,\n",
    " 2.383960, 2.390580, 2.397200, 2.403820, 2.410440, 2.417060, 2.423680,\n",
    " 2.430300, 2.436920, 2.443540, 2.450170, 2.456790, 2.463410, 2.470030,\n",
    " 2.476660, 2.483280, 2.489900, 2.496530, 2.503120, 2.509720, 2.516320,\n",
    " 2.522920, 2.529510, 2.536110, 2.542710, 2.549310, 2.555910, 2.562510,\n",
    " 2.569110, 2.575710, 2.582310, 2.588910, 2.595510, 2.602120, 2.608720,\n",
    " 2.615320, 2.621920, 2.628530, 2.635130, 2.641740, 2.648340, 2.654950,\n",
    " 2.661550, 2.668160, 2.674760, 2.681370, 2.687980, 2.694580, 2.701190,\n",
    " 2.760680, 2.767290, 2.773900, 2.780520, 2.787130, 2.793740, 2.800350,\n",
    " 2.806970, 2.813580, 2.820200, 2.826810, 2.833430, 2.840040, 2.846660,\n",
    " 2.853280, 2.859890, 2.866510, 2.873130, 2.879750, 2.886360, 2.892980,\n",
    " 2.899600, 2.906220, 2.912840, 2.919460, 2.926080, 2.932700, 2.939320,\n",
    " 2.945950, 2.952570, 2.959190, 2.965810, 2.972440, 2.979060, 2.985680,\n",
    " 2.992310, 2.998930, 3.005560, 3.012180, 3.018810, 3.025440, 3.032060,\n",
    " 3.038690, 3.045320, 3.051950, 3.058570, 3.065200, 3.071830, 3.078460,\n",
    " 3.085090, 3.091720, 3.098350, 3.104980, 3.111610, 3.118250, 3.124880,\n",
    " 3.131510, 3.138140, 3.144780, 3.151410, 3.158040, 3.164680, 3.171310,\n",
    " 3.177950, 3.184580, 3.191220, 3.197850, 3.204490, 3.211130, 3.217760,\n",
    " 3.224400, 3.231040, 3.237680, 3.244320, 3.250960, 3.257600, 3.264240,\n",
    " 3.270880, 3.277520, 3.284160, 3.290800, 3.297440, 3.304080, 3.310730,\n",
    " 3.317370, 3.324010, 3.330660, 3.337300, 3.343950, 3.350590, 3.357240,\n",
    " 3.363880, 3.370530, 3.377170, 3.383820, 3.390470, 3.397120, 3.403760,\n",
    " 3.410410, 3.417060, 3.423710, 3.430360, 3.437010, 3.443660, 3.450310,\n",
    " 3.456960, 3.463610, 3.470260, 3.476920, 3.483570, 3.490220, 3.496870,\n",
    " 3.503530, 3.510180, 3.516840, 3.523490, 3.530150, 3.536800, 3.543460,\n",
    " 3.550110, 3.556770, 3.563430, 3.570080, 3.576740, 3.583400, 3.590060,\n",
    " 3.596720, 3.603380, 3.610040, 3.616700, 3.623360, 3.630020, 3.636680,\n",
    " 3.643340, 3.650000, 3.656670, 3.663330, 3.669990, 3.676650, 3.683320,\n",
    " 3.689980, 3.696650, 3.703310, 3.709980, 3.716640, 3.723310, 3.729980,\n",
    " 3.736640, 3.743310, 3.749980, 3.756650, 3.763310, 3.769980, 3.776650,\n",
    " 3.783320, 3.789990, 3.796660, 3.803330, 3.810000, 3.816670, 3.823350,\n",
    " 3.830020, 3.836690, 3.843360, 3.850040, 3.856710, 3.863390, 3.870060,\n",
    " 3.876730, 3.883410, 3.890080, 3.896760, 3.903440, 3.910110, 3.916790,\n",
    " 3.923470, 3.930150, 3.936820, 4.000000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the bands that are to be written in the rest are to be ignored\n",
    "lowerBoundBand=ogWavelengthList.index(wavelengthList[0])\n",
    "upperBoundBand=ogWavelengthList.index(wavelengthList[-1])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all pixels in the destination array to no-Data (65535) so that when the denoised image is inserted everything else is automatically no data\n",
    "destinationDatacube[:]=65535.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder the axis of the datacube from  row,column,band to band,row,column\n",
    "despikedDatacube=np.moveaxis(despikedDatacube,-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the denoised array into the destination datacube\n",
    "destinationDatacube[:,rowLowerBound:rowUpperBound,colLowerBound:colUpperBound]=despikedDatacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the processed image on disk\n",
    "for i in range(destinationDatacube.shape[0]):\n",
    "    outBand=imageFile.GetRasterBand(i + 1)\n",
    "    outBand.WriteArray(destinationDatacube[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinationDatacube.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
